{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518ca145",
   "metadata": {},
   "source": [
    "# Text analysis workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148c08",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ICa2nh3mbflJCrJ4oKNUHWTZ9_vTJw8F?usp=sharing) (Fix link later!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add colab explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039a9d1",
   "metadata": {},
   "source": [
    "# Part 1: Set-up\n",
    "At the beginning of this notebook, we need to set up all of the libraries/packages (reusable python-programs other people have written) that we are going to use during. For this we use a common python-package manager called 'pip'. Pip takes care of downloading the right versions, and installing them on our computer, which in this case is a server that's standing in a google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dddebf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyalex in ./venv/lib/python3.12/site-packages (0.18)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from pyalex) (2.32.5)\n",
      "Requirement already satisfied: urllib3 in ./venv/lib/python3.12/site-packages (from pyalex) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->pyalex) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->pyalex) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->pyalex) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in ./venv/lib/python3.12/site-packages (0.5.9.post2)\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.12/site-packages (from umap-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./venv/lib/python3.12/site-packages (from umap-learn) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in ./venv/lib/python3.12/site-packages (from umap-learn) (1.7.1)\n",
      "Requirement already satisfied: numba>=0.51.2 in ./venv/lib/python3.12/site-packages (from umap-learn) (0.61.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in ./venv/lib/python3.12/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from umap-learn) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./venv/lib/python3.12/site-packages (from pynndescent>=0.5->umap-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datamapplot in ./venv/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: colorcet in ./venv/lib/python3.12/site-packages (from datamapplot) (3.1.0)\n",
      "Requirement already satisfied: colorspacious>=1.1 in ./venv/lib/python3.12/site-packages (from datamapplot) (1.1.2)\n",
      "Requirement already satisfied: dask<2025.0.1,>=2024.4.1 in ./venv/lib/python3.12/site-packages (from dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.1)\n",
      "Requirement already satisfied: datashader>=0.16 in ./venv/lib/python3.12/site-packages (from datamapplot) (0.18.2)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.12/site-packages (from datamapplot) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from datamapplot) (3.1.6)\n",
      "Requirement already satisfied: matplotlib>=3.8 in ./venv/lib/python3.12/site-packages (from datamapplot) (3.10.6)\n",
      "Requirement already satisfied: numba>=0.56 in ./venv/lib/python3.12/site-packages (from datamapplot) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.21 in ./venv/lib/python3.12/site-packages (from datamapplot) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.0 in ./venv/lib/python3.12/site-packages (from datamapplot) (2.3.2)\n",
      "Requirement already satisfied: pyarrow in ./venv/lib/python3.12/site-packages (from datamapplot) (21.0.0)\n",
      "Requirement already satisfied: pylabeladjust in ./venv/lib/python3.12/site-packages (from datamapplot) (0.1.13)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from datamapplot) (2.32.5)\n",
      "Requirement already satisfied: rcssmin>=1.1.2 in ./venv/lib/python3.12/site-packages (from datamapplot) (1.2.1)\n",
      "Requirement already satisfied: rjsmin>=1.2.2 in ./venv/lib/python3.12/site-packages (from datamapplot) (1.2.4)\n",
      "Requirement already satisfied: scikit-image>=0.22 in ./venv/lib/python3.12/site-packages (from datamapplot) (0.25.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in ./venv/lib/python3.12/site-packages (from datamapplot) (1.7.1)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.12/site-packages (from datamapplot) (4.4.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.12/site-packages (from datamapplot) (4.15.0)\n",
      "Requirement already satisfied: click>=8.1 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (25.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.0.0)\n",
      "Requirement already satisfied: lz4>=4.3.2 in ./venv/lib/python3.12/site-packages (from dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (4.4.4)\n",
      "Requirement already satisfied: multipledispatch in ./venv/lib/python3.12/site-packages (from datashader>=0.16->datamapplot) (1.0.0)\n",
      "Requirement already satisfied: param in ./venv/lib/python3.12/site-packages (from datashader>=0.16->datamapplot) (2.2.1)\n",
      "Requirement already satisfied: pyct in ./venv/lib/python3.12/site-packages (from datashader>=0.16->datamapplot) (0.5.0)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from datashader>=0.16->datamapplot) (1.16.1)\n",
      "Requirement already satisfied: xarray in ./venv/lib/python3.12/site-packages (from datashader>=0.16->datamapplot) (2025.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib>=3.8->datamapplot) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.56->datamapplot) (0.44.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas>=1.0->datamapplot) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas>=1.0->datamapplot) (2025.2)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from scikit-image>=0.22->datamapplot) (3.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in ./venv/lib/python3.12/site-packages (from scikit-image>=0.22->datamapplot) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./venv/lib/python3.12/site-packages (from scikit-image>=0.22->datamapplot) (2025.8.28)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./venv/lib/python3.12/site-packages (from scikit-image>=0.22->datamapplot) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.1->datamapplot) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.1->datamapplot) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->datamapplot) (3.0.2)\n",
      "Requirement already satisfied: Pyqtree<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from pylabeladjust->datamapplot) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in ./venv/lib/python3.12/site-packages (from pylabeladjust->datamapplot) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->datamapplot) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->datamapplot) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->datamapplot) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->datamapplot) (2025.8.3)\n",
      "Requirement already satisfied: locket in ./venv/lib/python3.12/site-packages (from partd>=1.4.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.8->datamapplot) (1.17.0)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.1.21)\n",
      "Requirement already satisfied: distributed==2024.12.1 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.1)\n",
      "Requirement already satisfied: bokeh>=3.1.0 in ./venv/lib/python3.12/site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.8.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in ./venv/lib/python3.12/site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.1.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./venv/lib/python3.12/site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (7.0.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in ./venv/lib/python3.12/site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in ./venv/lib/python3.12/site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./venv/lib/python3.12/site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (6.5.2)\n",
      "Requirement already satisfied: zict>=3.0.0 in ./venv/lib/python3.12/site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.0.0)\n",
      "Requirement already satisfied: narwhals>=1.13 in ./venv/lib/python3.12/site-packages (from bokeh>=3.1.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2.2.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in ./venv/lib/python3.12/site-packages (from bokeh>=3.1.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2025.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.12/site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers) (4.56.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.29)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./venv/lib/python3.12/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in ./venv/lib/python3.12/site-packages (from seaborn) (2.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./venv/lib/python3.12/site-packages (from seaborn) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: genieclust in ./venv/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: Cython in ./venv/lib/python3.12/site-packages (from genieclust) (3.1.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from genieclust) (2.2.6)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (from genieclust) (3.10.6)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (from genieclust) (1.7.1)\n",
      "Requirement already satisfied: quitefastmst in ./venv/lib/python3.12/site-packages (from genieclust) (0.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib->genieclust) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->genieclust) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->genieclust) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->genieclust) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->genieclust) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting litellm\n",
      "  Downloading litellm-1.76.1-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting aiohttp>=3.10 (from litellm)\n",
      "  Using cached aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from litellm) (8.2.1)\n",
      "Collecting fastuuid>=0.12.0 (from litellm)\n",
      "  Downloading fastuuid-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.8 kB)\n",
      "Collecting httpx>=0.23.0 (from litellm)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in ./venv/lib/python3.12/site-packages (from litellm) (3.1.6)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting openai>=1.99.5 (from litellm)\n",
      "  Downloading openai-1.102.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.0 (from litellm)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tokenizers in ./venv/lib/python3.12/site-packages (from litellm) (0.22.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10->litellm)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.10->litellm)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp>=3.10->litellm)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10->litellm)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10->litellm)\n",
      "  Downloading multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.10->litellm)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10->litellm)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting anyio (from httpx>=0.23.0->litellm)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->litellm)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->litellm)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
      "  Downloading rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.99.5->litellm)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.99.5->litellm)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai>=1.99.5->litellm)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai>=1.99.5->litellm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.12/site-packages (from openai>=1.99.5->litellm) (4.15.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.0->litellm)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.5.0->litellm)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.5.0->litellm)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2025.8.29)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.12/site-packages (from tokenizers->litellm) (0.34.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.5.0)\n",
      "Downloading litellm-1.76.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl (469 kB)\n",
      "Downloading fastuuid-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (247 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading openai-1.102.0-py3-none-any.whl (812 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-macosx_11_0_arm64.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.7/996.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached jiter-0.10.0-cp312-cp312-macosx_11_0_arm64.whl (320 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl (345 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl (89 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: zipp, typing-inspection, sniffio, rpds-py, python-dotenv, pydantic-core, propcache, multidict, jiter, h11, frozenlist, fastuuid, distro, attrs, annotated-types, aiohappyeyeballs, yarl, tiktoken, referencing, pydantic, importlib-metadata, httpcore, anyio, aiosignal, jsonschema-specifications, httpx, aiohttp, openai, jsonschema, litellm\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.10.0 attrs-25.3.0 distro-1.9.0 fastuuid-0.12.0 frozenlist-1.7.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 importlib-metadata-8.7.0 jiter-0.10.0 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 litellm-1.76.1 multidict-6.6.4 openai-1.102.0 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 referencing-0.36.2 rpds-py-0.27.1 sniffio-1.3.1 tiktoken-0.11.0 typing-inspection-0.4.1 yarl-1.20.1 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyalex\n",
    "!pip install umap-learn\n",
    "!pip install datamapplot\n",
    "!pip install sentence-transformers\n",
    "!pip install seaborn\n",
    "!pip install genieclust\n",
    "!pip install litellm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c4c0e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1344e34a",
   "metadata": {},
   "source": [
    "# Part 2: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Our data-handling library:\n",
    "import pandas as pd\n",
    "\n",
    "# Our visualisation library:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Our numerical library:\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import pyalex\n",
    "\n",
    "# Our mapping library:\n",
    "import umap\n",
    "import datamapplot\n",
    "from utils.openalex_utils import openalex_url_to_pyalex_query, process_records_to_df, get_records_from_dois, openalex_url_to_filename, download_openalex_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549c12e",
   "metadata": {},
   "source": [
    "# Part 3: Getting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186423a",
   "metadata": {},
   "source": [
    "## Part 3.1 OpenAlex-datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e54e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "openalex_url = 'https://openalex.org/works?page=1&filter=title_and_abstract.search:Aristotle,language:languages/en'\n",
    "\n",
    "dataset_df = download_openalex_records(openalex_url,\n",
    "                                       reduce_sample=True, \n",
    "                                       sample_reduction_method=\"n random samples\", \n",
    "                                       sample_size=5000, \n",
    "                                       seed_value=\"42\")\n",
    "\n",
    "\n",
    "# We filter for works that have an abstract:\n",
    "dataset_df = dataset_df[dataset_df['abstract'].str.len() > 10]\n",
    "\n",
    "text_data = list(dataset_df['abstract'])\n",
    "year_data = dataset_df['publication_year']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3fbd1",
   "metadata": {},
   "source": [
    "We can take a look at the data, by displaying the dataframe-object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7de8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2945543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2379379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a5b837",
   "metadata": {},
   "source": [
    "# Part 4: Using a language model \n",
    "We are now going to use a text-embedding model (a relatively small large language model) to transform the texts into a format which is easier to analyze mathematically. \n",
    "\n",
    "\n",
    "(BERT explaination.)  \n",
    "\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc184e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('thenlper/gte-small')\n",
    "embeddings = model.encode(text_data,show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4dcb4",
   "metadata": {},
   "source": [
    "This is what the resulting embeddings look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7040a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf9d456",
   "metadata": {},
   "source": [
    "# Part 5: doing dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, random_state=42,metric='cosine')\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "print(umap_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4a436",
   "metadata": {},
   "source": [
    "We can also look at the embeddings as a scatter-plot. Each data-point is one of our texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1],alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf0ac6",
   "metadata": {},
   "source": [
    "# Part 5: Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f342a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import genieclust\n",
    "g = genieclust.Genie(n_clusters=10, gini_threshold=0.3)\n",
    "cluster_labels = g.fit_predict(umap_embeddings)\n",
    "print(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1],c=cluster_labels,cmap='viridis',alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamapplot\n",
    "\n",
    "datamapplot.create_interactive_plot(\n",
    "    umap_embeddings,\n",
    "    hover_text=text_data,  # hover_text must be the 2nd positional\n",
    "  #  np.array([str(x+1) for x in cluster_labels]),  # label layer\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adfb4d",
   "metadata": {},
   "source": [
    "# Part 6: Labeling clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ac189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OpenAI API key from API_KEYS.txt file\n",
    "with open('API_KEYS.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('OPENAI:'):\n",
    "            openai_api_key = line.split(':', 1)[1].strip()\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"OPENAI API key not found in API_KEYS.txt\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bde17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling cluster 0 (309 texts)...\n",
      "Cluster 0: {\n",
      "  \"label\": \"Humanities Book Reviews\",\n",
      "  \"description\": \"Scholarly reviews and abstracts on religion, philosophy, and literature—often with a medieval or theological focus—covering figures from Dante to Protagoras and topics like divine embodiment, ethics, and intellectual history.\"\n",
      "}\n",
      "\n",
      "Labeling cluster 1 (597 texts)...\n",
      "Cluster 1: {\n",
      "  \"label\": \"Classical Rhetoric & Literature\",\n",
      "  \"description\": \"Scholarly discussions connecting philosophy and literature with an emphasis on rhetoric’s history and theory—especially Aristotelian influences—covering poetics, ethos/credibility, and classical frameworks shaping modern criticism and arts.\"\n",
      "}\n",
      "\n",
      "Labeling cluster 2 (860 texts)...\n",
      "Cluster 2: {\n",
      "  \"label\": \"Ancient philosophy and logic\",\n",
      "  \"description\": \"Historical and conceptual studies of philosophy from the Presocratics through Plato and Aristotle, focusing on logic, mathematics, and scientific explanation. Themes include the origins of logic, the problem of induction, plausible reasoning, critiques of Platonism, and the roots of science in philosophical inquiry, with figures like Aristotle and Frege prominent.\"\n",
      "}\n",
      "\n",
      "Labeling cluster 3 (678 texts)...\n",
      "Cluster 3: {\n",
      "  \"label\": \"Aristotelian Political Thought\",\n",
      "  \"description\": \"Scholarly works exploring classical Greek, especially Aristotelian, foundations of political science—teleology, causation, myth, and oligarchy—alongside themes like social comparison in rhetoric, religion’s role in governance, and implications for modern democracy.\"\n",
      "}\n",
      "\n",
      "Labeling cluster 4 (262 texts)...\n",
      "Cluster 4: {\n",
      "  \"label\": \"Aristotelian Philosophy of Mind\",\n",
      "  \"description\": \"Scholarly discussions centered on Aristotle’s De Anima—definitions of soul, phantasia, perception, and substantial form—along with critiques, historical receptions (patristic and Scholastic), and links to contemporary philosophy and neuroscience.\"\n",
      "}\n",
      "\n",
      "Labeling cluster 5 (230 texts)...\n",
      "Cluster 5: {\n",
      "  \"label\": \"Philosophical Hermeneutics and Critique\",\n",
      "  \"description\": \"Scholarly analyses of how classical and modern texts are interpreted and theorized—spanning Aristotle, Hegel, Marx, and Islamic thought—with attention to meaning, metaphysics, and applications to translation, gender, and culture.\"\n",
      "}\n",
      "\n",
      "Labeling cluster 6 (275 texts)...\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Create a function to label clusters using OpenAI\n",
    "def label_cluster(cluster_texts, cluster_id, n_samples=10):\n",
    "    # Randomly sample representative texts from the cluster (max 10 for efficiency)\n",
    "    sample_size = min(10, len(cluster_texts))\n",
    "    sample_texts = random.sample(cluster_texts, sample_size)\n",
    "    \n",
    "    # Truncate texts to 100 characters\n",
    "    sample_texts = [text[:1000] + \"...\" if len(text) > 1000 else text for text in sample_texts]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Below are randomly sampled texts from cluster {cluster_id}. Please analyze these texts and provide:\n",
    "    1. A short descriptive label (2-4 words) for this cluster\n",
    "    2. A brief description of the main theme\n",
    "\n",
    "    Texts:\n",
    "    {chr(10).join([f\"- {text[:200]}...\" if len(text) > 200 else f\"- {text}\" for text in sample_texts])}\n",
    "    \n",
    "    Please respond in JSON format:\n",
    "    {{\n",
    "        \"label\": \"[your label]\",\n",
    "        \"description\": \"[your description]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"content\": prompt, \"role\": \"user\"}]\n",
    "    response = completion(model=\"openai/gpt-5\", messages=messages, response_format={\"type\": \"json_object\"})\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Group texts by cluster\n",
    "cluster_groups = {}\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    if label not in cluster_groups:\n",
    "        cluster_groups[label] = []\n",
    "    cluster_groups[label].append(text_data[i])\n",
    "\n",
    "# Label each cluster\n",
    "cluster_info = {}\n",
    "for cluster_id, texts in cluster_groups.items():\n",
    "    print(f\"Labeling cluster {cluster_id} ({len(texts)} texts)...\")\n",
    "    label_info = label_cluster(texts, cluster_id, n_samples=5)\n",
    "    cluster_info[cluster_id] = label_info\n",
    "    print(f\"Cluster {cluster_id}: {label_info}\\n\")\n",
    "\n",
    "# Create a summary dataframe\n",
    "cluster_summary = []\n",
    "for cluster_id, info in cluster_info.items():\n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        parsed_info = json.loads(info)\n",
    "        label = parsed_info.get('label', 'Unknown')\n",
    "        description = parsed_info.get('description', 'No description available')\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # Fallback if JSON parsing fails\n",
    "        label = f\"Cluster {cluster_id}\"\n",
    "        description = str(info)\n",
    "    \n",
    "    cluster_summary.append({\n",
    "        'Cluster_ID': cluster_id,\n",
    "        'Size': len(cluster_groups[cluster_id]),\n",
    "        'Label': label,\n",
    "        'Description': description\n",
    "    })\n",
    "\n",
    "cluster_df = pd.DataFrame(cluster_summary)\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb7503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6dcefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff39dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56abe23b",
   "metadata": {},
   "source": [
    "# Part 7: Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca711f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabd654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5578a1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5bb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f0558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
